{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install datasets\n# !pip install transformers","metadata":{"id":"XmbX6vPI-89p","outputId":"849ed5fa-0bd1-4e01-dcbc-ec406a6c40b0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom datasets import load_dataset, concatenate_datasets\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding","metadata":{"id":"rdfCWnP0-rWW","execution":{"iopub.status.busy":"2022-06-06T10:16:28.697310Z","iopub.execute_input":"2022-06-06T10:16:28.697731Z","iopub.status.idle":"2022-06-06T10:16:35.946700Z","shell.execute_reply.started":"2022-06-06T10:16:28.697645Z","shell.execute_reply":"2022-06-06T10:16:35.945936Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Detect hardware\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\nexcept ValueError:\n    tpu = None\n    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n    \n# Select appropriate distribution strategy\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu) # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \nelif len(gpus) > 1:\n    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\nelif len(gpus) == 1:\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    print('Running on single GPU ', gpus[0].name)\nelse:\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    print('Running on CPU')\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"id":"wpG3pQ-JISZU","outputId":"1e37d4d9-bb60-4612-fb43-5637b9363c2f","execution":{"iopub.status.busy":"2022-06-06T10:16:38.687027Z","iopub.execute_input":"2022-06-06T10:16:38.687861Z","iopub.status.idle":"2022-06-06T10:16:43.398295Z","shell.execute_reply.started":"2022-06-06T10:16:38.687823Z","shell.execute_reply":"2022-06-06T10:16:43.397385Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Running on single GPU  /device:GPU:0\nNumber of accelerators:  1\n","output_type":"stream"},{"name":"stderr","text":"2022-06-06 10:16:38.758170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:38.759363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:38.760060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:38.762638: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-06-06 10:16:38.763010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:38.763794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:38.764495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:43.381651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:43.382551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:43.383210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 10:16:43.383791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# define batch size\nbatch_size_per_replica = 16\nbatch_size = batch_size_per_replica * strategy.num_replicas_in_sync\nprint('Batch size:', batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T10:16:43.399966Z","iopub.execute_input":"2022-06-06T10:16:43.400728Z","iopub.status.idle":"2022-06-06T10:16:43.405652Z","shell.execute_reply.started":"2022-06-06T10:16:43.400690Z","shell.execute_reply":"2022-06-06T10:16:43.404925Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Batch size: 16\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset(\"imdb\")\ndataset['valid'] = dataset.pop('test')\ndataset.pop('unsupervised')\ndataset","metadata":{"id":"pnDHFvjZ-yp_","outputId":"f20381d4-0a07-4e3a-f60a-381e82372da4","execution":{"iopub.status.busy":"2022-06-06T10:16:44.076769Z","iopub.execute_input":"2022-06-06T10:16:44.077497Z","iopub.status.idle":"2022-06-06T10:17:18.232344Z","shell.execute_reply.started":"2022-06-06T10:16:44.077459Z","shell.execute_reply":"2022-06-06T10:17:18.231399Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81463c2939994c9fb997ad988d2dc1a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f016164137ac4555968365a369a218fa"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"623f905ff06946b1b7ea175bf6e0c417"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28c96fb47cdb495c9a2071ae139f1be8"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    valid: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"sample_train = dataset['train'].shuffle(seed=32).select(range(1601))\nsample_valid = dataset['valid'].shuffle(seed=32).select(range(1600))\n\nfinal_ds = sample_train.train_test_split(train_size=1600)\nfinal_ds['valid'] = sample_valid\nfinal_ds.pop('test')\nfinal_ds","metadata":{"id":"NAMwHYdjK_CR","outputId":"052d10ea-6575-4935-eb24-1903c297863d","execution":{"iopub.status.busy":"2022-06-06T10:17:18.234238Z","iopub.execute_input":"2022-06-06T10:17:18.234619Z","iopub.status.idle":"2022-06-06T10:17:18.543613Z","shell.execute_reply.started":"2022-06-06T10:17:18.234582Z","shell.execute_reply":"2022-06-06T10:17:18.542884Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1600\n    })\n    valid: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1600\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint = 'distilbert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"id":"5Q17nqorBH-M","execution":{"iopub.status.busy":"2022-06-06T10:17:18.544740Z","iopub.execute_input":"2022-06-06T10:17:18.545179Z","iopub.status.idle":"2022-06-06T10:17:20.187174Z","shell.execute_reply.started":"2022-06-06T10:17:18.545140Z","shell.execute_reply":"2022-06-06T10:17:20.186369Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a481ec1465a248968ea2966fdc6d420f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f073604ca8247ce8ce1d060b8afba77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e9136c34bbd4d8dbb3847287bced6ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c970938e482c4792b248aab147b5c627"}},"metadata":{}}]},{"cell_type":"code","source":"model_max_len = tokenizer.model_max_length\nmodel_max_len","metadata":{"id":"w7HY2uiCFQ_5","outputId":"a6875c6a-8eb0-4e8d-c534-c9de31d7e969","execution":{"iopub.status.busy":"2022-06-06T10:17:20.188881Z","iopub.execute_input":"2022-06-06T10:17:20.189238Z","iopub.status.idle":"2022-06-06T10:17:20.194417Z","shell.execute_reply.started":"2022-06-06T10:17:20.189204Z","shell.execute_reply":"2022-06-06T10:17:20.193660Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"512"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n  examples = [example.lower() for example in examples['text']]\n  return tokenizer(examples, max_length=model_max_len, padding=True, truncation=True)\n\ntokenized_dataset = final_ds.map(tokenize_function, batched=True, remove_columns=['text'])\ntokenized_dataset","metadata":{"id":"clC9mt5-ETeM","outputId":"4c642a86-b1c2-4de1-f701-8f26a45d1c1c","execution":{"iopub.status.busy":"2022-06-06T10:17:22.707330Z","iopub.execute_input":"2022-06-06T10:17:22.707859Z","iopub.status.idle":"2022-06-06T10:17:26.548652Z","shell.execute_reply.started":"2022-06-06T10:17:22.707815Z","shell.execute_reply":"2022-06-06T10:17:26.547884Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e38b22a825744f8691e93122f50e5279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9800c52bd22d4c52b8e3919b7d0dccbf"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'attention_mask'],\n        num_rows: 1600\n    })\n    valid: Dataset({\n        features: ['label', 'input_ids', 'attention_mask'],\n        num_rows: 1600\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors='tf')\n\ntf_train_ds = tokenized_dataset['train'].to_tf_dataset(\n    columns=['input_ids', 'attention_mask'],\n    label_cols=['label'],\n    shuffle=True,\n    collate_fn=data_collator,\n    batch_size=batch_size,)\n\ntf_valid_ds = tokenized_dataset['valid'].to_tf_dataset(\n    columns=['input_ids', 'attention_mask'],\n    label_cols=['label'],\n    shuffle=False,\n    collate_fn=data_collator,\n    batch_size=batch_size,)","metadata":{"id":"SfuiY2fBFEe5","outputId":"9670e89d-144d-4398-f71b-59b6d3ff42db","execution":{"iopub.status.busy":"2022-06-06T10:17:29.967040Z","iopub.execute_input":"2022-06-06T10:17:29.967636Z","iopub.status.idle":"2022-06-06T10:17:31.717127Z","shell.execute_reply.started":"2022-06-06T10:17:29.967598Z","shell.execute_reply":"2022-06-06T10:17:31.716193Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for x in tf_train_ds.take(1):\n  print(x)","metadata":{"id":"GvJqeTo7FEhS","outputId":"ac6c8742-9c48-46b1-8f9b-7dcac02e3652","execution":{"iopub.status.busy":"2022-06-06T10:17:37.768505Z","iopub.execute_input":"2022-06-06T10:17:37.769179Z","iopub.status.idle":"2022-06-06T10:17:37.862180Z","shell.execute_reply.started":"2022-06-06T10:17:37.769144Z","shell.execute_reply":"2022-06-06T10:17:37.859356Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"({'input_ids': <tf.Tensor: shape=(16, 512), dtype=int64, numpy=\narray([[  101,  1012,  1012, ...,     0,     0,     0],\n       [  101, 17453,  5875, ...,     0,     0,     0],\n       [  101,  1045,  2572, ...,     0,     0,     0],\n       ...,\n       [  101,  2512,  2072, ...,     0,     0,     0],\n       [  101,  2023,  3185, ...,     0,     0,     0],\n       [  101,  1045,  5987, ...,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(16, 512), dtype=int64, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])>}, <tf.Tensor: shape=(16,), dtype=int64, numpy=array([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0])>)\n","output_type":"stream"},{"name":"stderr","text":"2022-06-06 10:17:37.808871: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"with strategy.scope():\n  model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)\n  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5))\n  \nmodel.fit(tf_train_ds, validation_data=tf_valid_ds, epochs=2)","metadata":{"id":"dkB-1ss-EThD","outputId":"0231478f-424a-409d-ba32-bc2410e4469a","execution":{"iopub.status.busy":"2022-06-06T10:17:43.808292Z","iopub.execute_input":"2022-06-06T10:17:43.809139Z","iopub.status.idle":"2022-06-06T10:20:44.361439Z","shell.execute_reply.started":"2022-06-06T10:17:43.809104Z","shell.execute_reply":"2022-06-06T10:20:44.360653Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de72da8f1ee8467d9272071375110af7"}},"metadata":{}},{"name":"stderr","text":"2022-06-06 10:18:00.427264: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\nSome layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_projector', 'vocab_transform', 'vocab_layer_norm']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_19']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2\n100/100 [==============================] - 81s 721ms/step - loss: 0.4332 - val_loss: 0.3765\nEpoch 2/2\n100/100 [==============================] - 71s 709ms/step - loss: 0.2058 - val_loss: 0.3008\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f001eaa21d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# TPU","metadata":{}},{"cell_type":"code","source":"train_input_ids = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['train']['input_ids']))\ntrain_attention_mask = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['train']['attention_mask']))\ntrain_labels = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['train']['label']))\ntrain_inputs = {'input_ids': train_input_ids, 'attention_mask':train_attention_mask}\ntrain_dataset = tf.data.Dataset.zip((train_inputs, train_labels)).shuffle(512).batch(batch_size).prefetch(-1)\n\n\nvalid_input_ids = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['valid']['input_ids']))\nvalid_attention_mask = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['valid']['attention_mask']))\nvalid_labels = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['valid']['label']))\nvalid_inputs = {'input_ids': valid_input_ids, 'attention_mask':valid_attention_mask}\nvalid_dataset = tf.data.Dataset.zip((valid_inputs, valid_labels)).batch(batch_size).prefetch(-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T10:13:56.391674Z","iopub.execute_input":"2022-06-06T10:13:56.391990Z","iopub.status.idle":"2022-06-06T10:13:58.348998Z","shell.execute_reply.started":"2022-06-06T10:13:56.391956Z","shell.execute_reply":"2022-06-06T10:13:58.348269Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n  model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)\n  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n                optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5))\n  \nmodel.fit(train_dataset, validation_data=valid_dataset, epochs=2)","metadata":{"id":"dRKxPhBZIvx3","execution":{"iopub.status.busy":"2022-06-06T10:14:02.152238Z","iopub.execute_input":"2022-06-06T10:14:02.152675Z","iopub.status.idle":"2022-06-06T10:15:39.956662Z","shell.execute_reply.started":"2022-06-06T10:14:02.152638Z","shell.execute_reply":"2022-06-06T10:15:39.955766Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2022-06-06 10:14:02.623600: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\nSome layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_layer_norm', 'activation_13', 'vocab_transform']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'classifier', 'pre_classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2\n13/13 [==============================] - 87s 3s/step - loss: 0.6722 - val_loss: 0.4876\nEpoch 2/2\n13/13 [==============================] - 3s 232ms/step - loss: 0.4173 - val_loss: 0.3493\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f06e8073990>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}