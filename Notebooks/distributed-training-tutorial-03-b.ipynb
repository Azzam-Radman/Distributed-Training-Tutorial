{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install datasets\n# !pip install transformers","metadata":{"id":"XmbX6vPI-89p","outputId":"849ed5fa-0bd1-4e01-dcbc-ec406a6c40b0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport numpy as np\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom datasets import load_dataset, concatenate_datasets\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding","metadata":{"id":"rdfCWnP0-rWW","execution":{"iopub.status.busy":"2022-06-06T16:00:04.715487Z","iopub.execute_input":"2022-06-06T16:00:04.715886Z","iopub.status.idle":"2022-06-06T16:00:11.903009Z","shell.execute_reply.started":"2022-06-06T16:00:04.715814Z","shell.execute_reply":"2022-06-06T16:00:11.902205Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Detect hardware\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\nexcept ValueError:\n    tpu = None\n    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n    \n# Select appropriate distribution strategy\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu) # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \nelif len(gpus) > 1:\n    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\nelif len(gpus) == 1:\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    print('Running on single GPU ', gpus[0].name)\nelse:\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    print('Running on CPU')\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"id":"wpG3pQ-JISZU","outputId":"1e37d4d9-bb60-4612-fb43-5637b9363c2f","execution":{"iopub.status.busy":"2022-06-06T16:00:18.170920Z","iopub.execute_input":"2022-06-06T16:00:18.172198Z","iopub.status.idle":"2022-06-06T16:00:22.543291Z","shell.execute_reply.started":"2022-06-06T16:00:18.172153Z","shell.execute_reply":"2022-06-06T16:00:22.541881Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Running on single GPU  /device:GPU:0\nNumber of accelerators:  1\n","output_type":"stream"},{"name":"stderr","text":"2022-06-06 16:00:18.236221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:18.237291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:18.238013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:18.240300: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-06-06 16:00:18.240632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:18.241438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:18.242203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:22.518535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:22.520027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:22.521187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-06 16:00:22.522261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# define batch size\nbatch_size_per_replica = 16\nbatch_size = batch_size_per_replica * strategy.num_replicas_in_sync\nprint('Batch size:', batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T16:00:22.546799Z","iopub.execute_input":"2022-06-06T16:00:22.547733Z","iopub.status.idle":"2022-06-06T16:00:22.556494Z","shell.execute_reply.started":"2022-06-06T16:00:22.547696Z","shell.execute_reply":"2022-06-06T16:00:22.554956Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Batch size: 16\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset(\"imdb\")\ndataset['valid'] = dataset.pop('test')\ndataset.pop('unsupervised')\ndataset","metadata":{"id":"pnDHFvjZ-yp_","outputId":"f20381d4-0a07-4e3a-f60a-381e82372da4","execution":{"iopub.status.busy":"2022-06-06T16:00:22.558726Z","iopub.execute_input":"2022-06-06T16:00:22.559470Z","iopub.status.idle":"2022-06-06T16:01:04.394987Z","shell.execute_reply.started":"2022-06-06T16:00:22.559280Z","shell.execute_reply":"2022-06-06T16:01:04.394231Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c87807b1b04b5e8cea8eab5fa14329"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05d92233f38e473d84926f1973dc4561"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b22cb0205d4b4a4cb3e62869332b7eac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab210a14731145d291387aa2fbf420d3"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    valid: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"sample_train = dataset['train'].shuffle(seed=32).select(range(1601))\nsample_valid = dataset['valid'].shuffle(seed=32).select(range(1600))\n\nfinal_ds = sample_train.train_test_split(train_size=1600)\nfinal_ds['valid'] = sample_valid\nfinal_ds.pop('test')\nfinal_ds","metadata":{"id":"NAMwHYdjK_CR","outputId":"052d10ea-6575-4935-eb24-1903c297863d","execution":{"iopub.status.busy":"2022-06-06T16:01:04.396830Z","iopub.execute_input":"2022-06-06T16:01:04.397588Z","iopub.status.idle":"2022-06-06T16:01:04.678304Z","shell.execute_reply.started":"2022-06-06T16:01:04.397551Z","shell.execute_reply":"2022-06-06T16:01:04.677554Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1600\n    })\n    valid: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1600\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint = 'distilbert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"id":"5Q17nqorBH-M","execution":{"iopub.status.busy":"2022-06-06T16:01:04.679652Z","iopub.execute_input":"2022-06-06T16:01:04.680027Z","iopub.status.idle":"2022-06-06T16:01:20.036296Z","shell.execute_reply.started":"2022-06-06T16:01:04.679990Z","shell.execute_reply":"2022-06-06T16:01:20.035341Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f729125837a949dc8aa082c57646e035"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5670464d33b24463894ff9834ce05550"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"476e5dfea36d4d2a827fd15160549add"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5068d70d571d4eb89ac72052dfce7b39"}},"metadata":{}}]},{"cell_type":"code","source":"model_max_len = tokenizer.model_max_length\nmodel_max_len","metadata":{"id":"w7HY2uiCFQ_5","outputId":"a6875c6a-8eb0-4e8d-c534-c9de31d7e969","execution":{"iopub.status.busy":"2022-06-06T16:01:20.037828Z","iopub.execute_input":"2022-06-06T16:01:20.038178Z","iopub.status.idle":"2022-06-06T16:01:20.043333Z","shell.execute_reply.started":"2022-06-06T16:01:20.038141Z","shell.execute_reply":"2022-06-06T16:01:20.042681Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"512"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    examples = [example.lower() for example in examples['text']]\n    return tokenizer(examples, max_length=model_max_len, padding=True, truncation=True)\n\ntokenized_dataset = final_ds.map(tokenize_function, batched=True, remove_columns=['text'])\ntokenized_dataset","metadata":{"id":"clC9mt5-ETeM","outputId":"4c642a86-b1c2-4de1-f701-8f26a45d1c1c","execution":{"iopub.status.busy":"2022-06-06T16:01:20.044656Z","iopub.execute_input":"2022-06-06T16:01:20.045222Z","iopub.status.idle":"2022-06-06T16:01:23.743304Z","shell.execute_reply.started":"2022-06-06T16:01:20.045186Z","shell.execute_reply":"2022-06-06T16:01:23.742472Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c29b2794a0194954af28e3470ea4cad0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68f839d4c5dc461c8d1239b18ee6dd98"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'attention_mask'],\n        num_rows: 1600\n    })\n    valid: Dataset({\n        features: ['label', 'input_ids', 'attention_mask'],\n        num_rows: 1600\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# GPU","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors='tf')\n\ntf_train_ds = tokenized_dataset['train'].to_tf_dataset(\n    columns=['input_ids', 'attention_mask'],\n    label_cols=['label'],\n    shuffle=True,\n    collate_fn=data_collator,\n    batch_size=batch_size,)\n\ntf_valid_ds = tokenized_dataset['valid'].to_tf_dataset(\n    columns=['input_ids', 'attention_mask'],\n    label_cols=['label'],\n    shuffle=False,\n    collate_fn=data_collator,\n    batch_size=batch_size,)","metadata":{"id":"SfuiY2fBFEe5","outputId":"9670e89d-144d-4398-f71b-59b6d3ff42db","execution":{"iopub.status.busy":"2022-06-06T16:01:23.744616Z","iopub.execute_input":"2022-06-06T16:01:23.745400Z","iopub.status.idle":"2022-06-06T16:01:25.365013Z","shell.execute_reply.started":"2022-06-06T16:01:23.745363Z","shell.execute_reply":"2022-06-06T16:01:25.364226Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for x in tf_train_ds.take(1):\n  print(x)","metadata":{"id":"GvJqeTo7FEhS","outputId":"ac6c8742-9c48-46b1-8f9b-7dcac02e3652","execution":{"iopub.status.busy":"2022-06-06T16:01:25.366268Z","iopub.execute_input":"2022-06-06T16:01:25.366929Z","iopub.status.idle":"2022-06-06T16:01:25.447149Z","shell.execute_reply.started":"2022-06-06T16:01:25.366893Z","shell.execute_reply":"2022-06-06T16:01:25.446347Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"({'input_ids': <tf.Tensor: shape=(16, 512), dtype=int64, numpy=\narray([[ 101, 1045, 2293, ...,    0,    0,    0],\n       [ 101, 1045, 2572, ..., 2065, 2017,  102],\n       [ 101, 1045, 2514, ...,    0,    0,    0],\n       ...,\n       [ 101, 1996, 3865, ...,    0,    0,    0],\n       [ 101, 2728, 2139, ...,    0,    0,    0],\n       [ 101, 4283, 2000, ...,    0,    0,    0]])>, 'attention_mask': <tf.Tensor: shape=(16, 512), dtype=int64, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])>}, <tf.Tensor: shape=(16,), dtype=int64, numpy=array([0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])>)\n","output_type":"stream"},{"name":"stderr","text":"2022-06-06 16:01:25.399042: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"with strategy.scope():\n    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T16:01:25.449739Z","iopub.execute_input":"2022-06-06T16:01:25.450080Z","iopub.status.idle":"2022-06-06T16:01:26.489446Z","shell.execute_reply.started":"2022-06-06T16:01:25.450052Z","shell.execute_reply":"2022-06-06T16:01:26.488687Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(x, y):\n    with tf.GradientTape() as tape:\n        logits = model(x, training=True)[0]\n        loss = loss_object(y, logits)\n        \n    gradients = tape.gradient(loss, model.trainable_weights)\n    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n    return loss\n\n@tf.function\ndef valid_step(x, y):\n    logits = model(x, training=False)[0]\n    loss = loss_object(y, logits)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-06-06T16:01:26.490881Z","iopub.execute_input":"2022-06-06T16:01:26.491222Z","iopub.status.idle":"2022-06-06T16:01:26.501330Z","shell.execute_reply.started":"2022-06-06T16:01:26.491187Z","shell.execute_reply":"2022-06-06T16:01:26.499728Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nwith strategy.scope():\n    model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)\n\nnum_epochs = 2\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch+1}/{num_epochs} ====================>')\n    train_losses = []\n    for x, y in tqdm(tf_train_ds, total=len(tf_train_ds)):\n        train_loss = train_step(x, y)\n        train_losses.append(train_loss)\n    print('Train Loss:', np.mean(train_losses))\n        \n    valid_losses = []\n    for x, y in tqdm(tf_valid_ds, total=len(tf_valid_ds)):\n        valid_loss = valid_step(x, y)\n        valid_losses.append(valid_loss)\n    print('Valid Loss:', np.mean(valid_losses))","metadata":{"id":"dkB-1ss-EThD","outputId":"0231478f-424a-409d-ba32-bc2410e4469a","execution":{"iopub.status.busy":"2022-06-06T16:01:26.503580Z","iopub.execute_input":"2022-06-06T16:01:26.504389Z","iopub.status.idle":"2022-06-06T16:04:38.272190Z","shell.execute_reply.started":"2022-06-06T16:01:26.504353Z","shell.execute_reply":"2022-06-06T16:04:38.271347Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc998f9223c14cda91a43380131a6571"}},"metadata":{}},{"name":"stderr","text":"2022-06-06 16:02:04.925243: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\nSome layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_transform', 'activation_13', 'vocab_layer_norm']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_19']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2 ====================>\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:58<00:00,  1.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.43121597\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:20<00:00,  4.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Valid Loss: 0.28809527\nEpoch 2/2 ====================>\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:51<00:00,  1.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.23885876\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:20<00:00,  4.88it/s]","output_type":"stream"},{"name":"stdout","text":"Valid Loss: 0.28966174\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TPU","metadata":{}},{"cell_type":"code","source":"train_input_ids = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['train']['input_ids']))\ntrain_attention_mask = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['train']['attention_mask']))\ntrain_labels = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['train']['label']))\ntrain_inputs = {'input_ids': train_input_ids, 'attention_mask':train_attention_mask}\ntrain_dataset = tf.data.Dataset.zip((train_inputs, train_labels)).shuffle(512).batch(batch_size).prefetch(-1)\n\n\nvalid_input_ids = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['valid']['input_ids']))\nvalid_attention_mask = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['valid']['attention_mask']))\nvalid_labels = tf.data.Dataset.from_tensor_slices(tf.constant(tokenized_dataset['valid']['label']))\nvalid_inputs = {'input_ids': valid_input_ids, 'attention_mask':valid_attention_mask}\nvalid_dataset = tf.data.Dataset.zip((valid_inputs, valid_labels)).batch(batch_size).prefetch(-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T15:50:34.765589Z","iopub.execute_input":"2022-06-06T15:50:34.765877Z","iopub.status.idle":"2022-06-06T15:50:36.845527Z","shell.execute_reply.started":"2022-06-06T15:50:34.765839Z","shell.execute_reply":"2022-06-06T15:50:36.844707Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction='none')\n    valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T15:56:22.054942Z","iopub.execute_input":"2022-06-06T15:56:22.055761Z","iopub.status.idle":"2022-06-06T15:56:22.101442Z","shell.execute_reply.started":"2022-06-06T15:56:22.055710Z","shell.execute_reply":"2022-06-06T15:56:22.100548Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def compute_loss(y, logits):\n        per_example_loss = loss_object(y, logits)\n        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T15:56:22.510927Z","iopub.execute_input":"2022-06-06T15:56:22.511256Z","iopub.status.idle":"2022-06-06T15:56:22.516351Z","shell.execute_reply.started":"2022-06-06T15:56:22.511223Z","shell.execute_reply":"2022-06-06T15:56:22.515468Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def train_step(batch):\n    x, y = batch\n    with tf.GradientTape() as tape:\n        logits = model(x, training=True)[0]\n        loss = compute_loss(y, logits)\n        \n    gradients = tape.gradient(loss, model.trainable_weights)\n    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n    return loss\n\ndef valid_step(batch):\n    x, y = batch\n    logits = model(x, training=False)[0]\n    loss = loss_object(y, logits)\n    \n    valid_loss.update_state(loss)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T15:56:34.892059Z","iopub.execute_input":"2022-06-06T15:56:34.892679Z","iopub.status.idle":"2022-06-06T15:56:34.901019Z","shell.execute_reply.started":"2022-06-06T15:56:34.892627Z","shell.execute_reply":"2022-06-06T15:56:34.900061Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef dist_train_step(batch):\n    per_replica_losses = strategy.run(train_step, args=(batch,))\n    return strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)\n\n@tf.function\ndef dist_valid_step(batch):\n    return strategy.run(valid_step, args=(batch,))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T15:56:36.502083Z","iopub.execute_input":"2022-06-06T15:56:36.502618Z","iopub.status.idle":"2022-06-06T15:56:36.960938Z","shell.execute_reply.started":"2022-06-06T15:56:36.502576Z","shell.execute_reply":"2022-06-06T15:56:36.960145Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nwith strategy.scope():\n    model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)\n    \nnum_epochs = 2\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch+1}/{num_epochs} ====================>')\n    train_losses = []\n    for batch in tqdm(train_dataset, total=len(train_dataset)):\n        x, y = batch\n        y = tf.expand_dims(y, axis=-1)\n        train_losses.append(dist_train_step((x, y)).numpy())\n    print('Train Loss:', np.mean(train_losses))\n\n    for batch in tqdm(valid_dataset, total=len(valid_dataset)):\n        x, y = batch\n        y = tf.expand_dims(y, axis=-1)\n        dist_valid_step((x, y))\n    print('Valid Loss:', valid_loss.result().numpy())\n    valid_loss.reset_states()","metadata":{"id":"dRKxPhBZIvx3","execution":{"iopub.status.busy":"2022-06-06T15:56:36.962889Z","iopub.execute_input":"2022-06-06T15:56:36.963488Z","iopub.status.idle":"2022-06-06T15:58:34.458237Z","shell.execute_reply.started":"2022-06-06T15:56:36.963447Z","shell.execute_reply":"2022-06-06T15:58:34.457440Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'classifier', 'pre_classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2 ====================>\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [01:22<00:00, 10.20s/it]2022-06-06 15:58:06.685662: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 48791, Output num: 0\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1654531086.685356802\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 48791, Output num: 0\",\"grpc_status\":3}\n100%|██████████| 13/13 [01:22<00:00,  6.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5844382\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:14<00:00,  1.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Valid Loss: 0.3992977\nEpoch 2/2 ====================>\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:10<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.29617876\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:02<00:00,  4.51it/s]","output_type":"stream"},{"name":"stdout","text":"Valid Loss: 0.31714994\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}